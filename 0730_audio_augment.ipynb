{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447be0e1-2559-4853-83b3-1cd071e0fad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/clim-lab/바탕화면/main_drive/jiwon/retrieval'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from glob import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch_poly_lr_decay import PolynomialLRDecay\n",
    "from torchvision import models\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "import random\n",
    "import torchaudio\n",
    "\n",
    "from tools.file_io import load_csv_file\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45bca14-fe57-4065-98dc-b3ceef0c5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.audio_augment import RandomClip, RandomSpeedChange, RandomBackgroundNoise, ComposeTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fb1970-90a5-4f66-8fca-1c74edc6d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "torch.set_num_threads(8)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca65e573-cd84-4e11-967f-823140bc94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0005,  0.0007,  0.0007,  ..., -0.0023, -0.0020, -0.0016]])\n",
      "torch.Size([1, 1261260])\n",
      "[ 0.00042238  0.00072047  0.00072089 ... -0.00280746 -0.00228519\n",
      " -0.00202156]\n",
      "(630630,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('file_name', ' Ambience Birds.wav'),\n",
       "              ('caption',\n",
       "               'A wild assortment of birds are chirping and calling out in nature.')]),\n",
       " OrderedDict([('file_name', ' Ambience Birds.wav'),\n",
       "              ('caption',\n",
       "               'Several different types of bird are tweeting and making calls.')])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ambience Birds.wav</td>\n",
       "      <td>A wild assortment of birds are chirping and ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience Birds.wav</td>\n",
       "      <td>Several different types of bird are tweeting a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ambience Birds.wav</td>\n",
       "      <td>Birds tweeting and chirping happily, engine in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambience Birds.wav</td>\n",
       "      <td>An assortment of  wild birds are chirping and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambience Birds.wav</td>\n",
       "      <td>Birds are chirping and making loud bird noises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19190</th>\n",
       "      <td>zippers01.wav</td>\n",
       "      <td>A jacket or bag is being zipped and unzipped.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19191</th>\n",
       "      <td>zippers01.wav</td>\n",
       "      <td>A long zipper is clasped frequently back and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19192</th>\n",
       "      <td>zippers01.wav</td>\n",
       "      <td>A zipper to a suitcase is being opened and clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>zippers01.wav</td>\n",
       "      <td>Long zipper being zipped back and forth multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19194</th>\n",
       "      <td>zippers01.wav</td>\n",
       "      <td>The zipper is opened and closed at a slow pace.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19195 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_name                                            caption\n",
       "0       Ambience Birds.wav  A wild assortment of birds are chirping and ca...\n",
       "1       Ambience Birds.wav  Several different types of bird are tweeting a...\n",
       "2       Ambience Birds.wav  Birds tweeting and chirping happily, engine in...\n",
       "3       Ambience Birds.wav  An assortment of  wild birds are chirping and ...\n",
       "4       Ambience Birds.wav    Birds are chirping and making loud bird noises.\n",
       "...                    ...                                                ...\n",
       "19190        zippers01.wav      A jacket or bag is being zipped and unzipped.\n",
       "19191        zippers01.wav  A long zipper is clasped frequently back and f...\n",
       "19192        zippers01.wav  A zipper to a suitcase is being opened and clo...\n",
       "19193        zippers01.wav  Long zipper being zipped back and forth multip...\n",
       "19194        zippers01.wav    The zipper is opened and closed at a slow pace.\n",
       "\n",
       "[19195 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "wav_path = os.listdir('./data/Clotho/waveforms/train/')\n",
    "\n",
    "audio_ex1, sr1 = torchaudio.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]))\n",
    "print(audio_ex1)\n",
    "print(audio_ex1.shape)\n",
    "\n",
    "audio_ex2, sr2 = librosa.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]))\n",
    "print(audio_ex2)\n",
    "print(audio_ex2.shape)\n",
    "\n",
    "data_path = '/home/clim-lab/바탕화면/main_drive/jiwon/retrieval/data/Clotho'\n",
    "#csv_path = os.path.join(data_path, 'csv_files/train.csv')\n",
    "csv_path = os.path.join(data_path, 'csv_files/')\n",
    "\n",
    "#csv_path = './data/Clotho/csv_files/'\n",
    "trains_aug = os.path.join(csv_path, 'train_melt.csv')\n",
    "vals_c = os.path.join(csv_path, 'val.csv')\n",
    "\n",
    "train_csv_list = load_csv_file(os.path.join(csv_path, 'train_melt.csv'))\n",
    "display(train_csv_list[:2])\n",
    "display(pd.DataFrame(train_csv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4707bbc8-d261-4d0d-8f9a-966f7452f339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0005,  0.0007,  0.0007,  ..., -0.0023, -0.0020, -0.0016]]), 44100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4089a7f6-1255-422c-98a2-6e8ce664d4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00042238,  0.00072047,  0.00072089, ..., -0.00280746,\n",
       "        -0.00228519, -0.00202156], dtype=float32),\n",
       " 22050)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e3176d3-e051-47bd-8c3a-4a90cb8a9577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0004,  0.0007,  0.0007,  ..., -0.0023, -0.0022, -0.0018]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 915200])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00042718,  0.00074288,  0.00065001, ..., -0.00224547,\n",
       "       -0.00219583, -0.00178362], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(915200,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1, s1 = torchaudio.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]))\n",
    "a1_trans = torchaudio.functional.resample(a1, orig_freq=44100, new_freq = 32000)\n",
    "a1_trans.reshape(-1).numpy()\n",
    "a2, s2 = librosa.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]), sr=32000)\n",
    "\n",
    "display(a1_trans)\n",
    "display(a1_trans.shape)\n",
    "display(a2)\n",
    "display(a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcae652a-0a43-43e8-bd35-d51f90859d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_name': array(['Distorted AM Radio noise.wav', 'Paper_Parchment_Rustling.wav',\n",
      "       '03 Whales Slowing Down.wav', ...,\n",
      "       'cold waterdrops in a hot pot.wav',\n",
      "       'Dry leaves falling on cement floor.wav', 'Wood chips.wav'],\n",
      "      dtype='<U133'), 'captions': array([['a muddled noise of broken channel of the tv',\n",
      "        'a television blares the rhythm of a static tv ',\n",
      "        'loud television static dips in and out of focus',\n",
      "        'the loud buzz of static constantly changes pitch and volume ',\n",
      "        'heavy static and the beginnings of a signal on a transistor radio'],\n",
      "       ['a person is turning a map over and over ',\n",
      "        'a person is very carefully rapping a gift for someone else ',\n",
      "        'a person is very carefully wrapping a gift for someone else ',\n",
      "        'he sighed as he turned the pages of the book stopping to scan the information ',\n",
      "        'papers are being turned stopped then turned again and someone is breathing '],\n",
      "       ['several barnyard animals mooing in a barn while it rains outside ',\n",
      "        'the vocalization of several whales along with the clicking of large numbers of shrimp reverberated below in the water ',\n",
      "        'underwater large numbers of shrimp clicking and several whales vocalizing ',\n",
      "        'whales sing to one another over the flowing water in the distance ',\n",
      "        'wales sing to one another with water flowing in the background'],\n",
      "       ...,\n",
      "       ['someone is flipping over food on a hot grill ',\n",
      "        'someone is flipping over food above a hot grill ',\n",
      "        'all recorded audio is drowned out by the loudness of the static ',\n",
      "        'someone waters down a boat with a high pressure stream of water ',\n",
      "        'a match is lit then another match is lit '],\n",
      "       ['tapping noises are being made before paper is being crumpled ',\n",
      "        'repeated tapping hits a hard surface and multiple papers shuffle ',\n",
      "        'a person is typing and pauses a few times in between strokes',\n",
      "        'they are continually dropping clips on the table ',\n",
      "        'sticks crunch and break while being walked on '],\n",
      "       ['some pounding in a room follows breaking of material that is not metal ',\n",
      "        'a stack of wooden blocks fall over and crash to the floor ',\n",
      "        'they are knocking down the toy blocks of the kid ',\n",
      "        'small blocks or chips are moving around and a muffled shuffling ',\n",
      "        'crushing up food to make a dish for others']], dtype='<U145')}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>caption_3</th>\n",
       "      <th>caption_4</th>\n",
       "      <th>caption_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Distorted AM Radio noise.wav</td>\n",
       "      <td>A muddled noise of broken channel of the TV</td>\n",
       "      <td>A television blares the rhythm of a static TV.</td>\n",
       "      <td>Loud television static dips in and out of focus</td>\n",
       "      <td>The loud buzz of static constantly changes pit...</td>\n",
       "      <td>heavy static and the beginnings of a signal on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paper_Parchment_Rustling.wav</td>\n",
       "      <td>A person is turning a map over and over.</td>\n",
       "      <td>A person is very carefully rapping a gift for ...</td>\n",
       "      <td>A person is very carefully wrapping a gift for...</td>\n",
       "      <td>He sighed as he turned the pages of the book, ...</td>\n",
       "      <td>papers are being turned, stopped, then turned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03 Whales Slowing Down.wav</td>\n",
       "      <td>Several barnyard animals mooing in a barn whil...</td>\n",
       "      <td>The vocalization of several whales, along with...</td>\n",
       "      <td>Underwater, large numbers of shrimp clicking a...</td>\n",
       "      <td>Whales sing to one another over the flowing wa...</td>\n",
       "      <td>wales sing to one another with water flowing i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rope tied to boat in port.wav</td>\n",
       "      <td>An office chair is squeaking as someone bends ...</td>\n",
       "      <td>Popping and squeaking gradually tapers off to ...</td>\n",
       "      <td>Someone is opening a creaky door slowly while ...</td>\n",
       "      <td>Squeaking and popping followed by gradual popp...</td>\n",
       "      <td>an office chair is squeaking as someone leans ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carpenter bee.wav</td>\n",
       "      <td>A flying bee is buzzing loudly around an objec...</td>\n",
       "      <td>An annoying fly is buzzing loudly and consiste...</td>\n",
       "      <td>An insect buzzing in the foreground as birds c...</td>\n",
       "      <td>An insect trapped in a spider web struggles, b...</td>\n",
       "      <td>Outdoors, insect trapped in a spider web and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>Metallic Ping CPU Heatsink.wav</td>\n",
       "      <td>Tools are being tried to make different sounds.</td>\n",
       "      <td>The metallic clang is made at different and va...</td>\n",
       "      <td>One at a time the metal chimes are being chimed.</td>\n",
       "      <td>A metallic clang is made at various pitches.</td>\n",
       "      <td>Metal chimes being chimed one at a time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>Fumbling.wav</td>\n",
       "      <td>multiple items are picked up, and a tin pan is...</td>\n",
       "      <td>They are sorting through objects and dropping ...</td>\n",
       "      <td>A person works moving cans and other items and...</td>\n",
       "      <td>Cans and items are being moved around clunking...</td>\n",
       "      <td>Going through all of the trash can noisily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>cold waterdrops in a hot pot.wav</td>\n",
       "      <td>Someone is flipping over food on a hot grill.</td>\n",
       "      <td>Someone is flipping over food above a hot grill.</td>\n",
       "      <td>All recorded audio is drowned out by the loudn...</td>\n",
       "      <td>Someone waters down a boat with a high pressur...</td>\n",
       "      <td>A match is lit, then another match is lit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>Dry leaves falling on cement floor.wav</td>\n",
       "      <td>Tapping noises are being made before paper is ...</td>\n",
       "      <td>Repeated tapping hits a hard surface and multi...</td>\n",
       "      <td>A person is typing and pauses a few times in b...</td>\n",
       "      <td>They are continually dropping clips on the table.</td>\n",
       "      <td>Sticks crunch and break while being walked on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Wood chips.wav</td>\n",
       "      <td>Some pounding in a room follows breaking of ma...</td>\n",
       "      <td>A stack of wooden blocks fall over and crash t...</td>\n",
       "      <td>They are knocking down the toy blocks of the kid.</td>\n",
       "      <td>Small blocks or chips are moving around and a ...</td>\n",
       "      <td>Crushing up food to make a dish for others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3839 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_name  \\\n",
       "0               Distorted AM Radio noise.wav   \n",
       "1               Paper_Parchment_Rustling.wav   \n",
       "2                 03 Whales Slowing Down.wav   \n",
       "3              Rope tied to boat in port.wav   \n",
       "4                          carpenter bee.wav   \n",
       "...                                      ...   \n",
       "3834          Metallic Ping CPU Heatsink.wav   \n",
       "3835                            Fumbling.wav   \n",
       "3836        cold waterdrops in a hot pot.wav   \n",
       "3837  Dry leaves falling on cement floor.wav   \n",
       "3838                          Wood chips.wav   \n",
       "\n",
       "                                              caption_1  \\\n",
       "0           A muddled noise of broken channel of the TV   \n",
       "1              A person is turning a map over and over.   \n",
       "2     Several barnyard animals mooing in a barn whil...   \n",
       "3     An office chair is squeaking as someone bends ...   \n",
       "4     A flying bee is buzzing loudly around an objec...   \n",
       "...                                                 ...   \n",
       "3834    Tools are being tried to make different sounds.   \n",
       "3835  multiple items are picked up, and a tin pan is...   \n",
       "3836      Someone is flipping over food on a hot grill.   \n",
       "3837  Tapping noises are being made before paper is ...   \n",
       "3838  Some pounding in a room follows breaking of ma...   \n",
       "\n",
       "                                              caption_2  \\\n",
       "0        A television blares the rhythm of a static TV.   \n",
       "1     A person is very carefully rapping a gift for ...   \n",
       "2     The vocalization of several whales, along with...   \n",
       "3     Popping and squeaking gradually tapers off to ...   \n",
       "4     An annoying fly is buzzing loudly and consiste...   \n",
       "...                                                 ...   \n",
       "3834  The metallic clang is made at different and va...   \n",
       "3835  They are sorting through objects and dropping ...   \n",
       "3836   Someone is flipping over food above a hot grill.   \n",
       "3837  Repeated tapping hits a hard surface and multi...   \n",
       "3838  A stack of wooden blocks fall over and crash t...   \n",
       "\n",
       "                                              caption_3  \\\n",
       "0       Loud television static dips in and out of focus   \n",
       "1     A person is very carefully wrapping a gift for...   \n",
       "2     Underwater, large numbers of shrimp clicking a...   \n",
       "3     Someone is opening a creaky door slowly while ...   \n",
       "4     An insect buzzing in the foreground as birds c...   \n",
       "...                                                 ...   \n",
       "3834   One at a time the metal chimes are being chimed.   \n",
       "3835  A person works moving cans and other items and...   \n",
       "3836  All recorded audio is drowned out by the loudn...   \n",
       "3837  A person is typing and pauses a few times in b...   \n",
       "3838  They are knocking down the toy blocks of the kid.   \n",
       "\n",
       "                                              caption_4  \\\n",
       "0     The loud buzz of static constantly changes pit...   \n",
       "1     He sighed as he turned the pages of the book, ...   \n",
       "2     Whales sing to one another over the flowing wa...   \n",
       "3     Squeaking and popping followed by gradual popp...   \n",
       "4     An insect trapped in a spider web struggles, b...   \n",
       "...                                                 ...   \n",
       "3834       A metallic clang is made at various pitches.   \n",
       "3835  Cans and items are being moved around clunking...   \n",
       "3836  Someone waters down a boat with a high pressur...   \n",
       "3837  They are continually dropping clips on the table.   \n",
       "3838  Small blocks or chips are moving around and a ...   \n",
       "\n",
       "                                              caption_5  \n",
       "0     heavy static and the beginnings of a signal on...  \n",
       "1     papers are being turned, stopped, then turned ...  \n",
       "2     wales sing to one another with water flowing i...  \n",
       "3     an office chair is squeaking as someone leans ...  \n",
       "4     Outdoors, insect trapped in a spider web and t...  \n",
       "...                                                 ...  \n",
       "3834           Metal chimes being chimed one at a time.  \n",
       "3835        Going through all of the trash can noisily.  \n",
       "3836         A match is lit, then another match is lit.  \n",
       "3837     Sticks crunch and break while being walked on.  \n",
       "3838         Crushing up food to make a dish for others  \n",
       "\n",
       "[3839 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import librosa\n",
    "from re import sub\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from tools.file_io import load_csv_file, write_pickle_file\n",
    "\n",
    "def load_metadata(dataset, csv_file):\n",
    "    \"\"\"Load meta data of Clotho\n",
    "    \"\"\"\n",
    "    if dataset == 'AudioCaps' and 'train' in csv_file:\n",
    "        caption_field = None\n",
    "    else:\n",
    "        caption_field = ['caption_{}'.format(i) for i in range(1, 6)]\n",
    "    csv_list = load_csv_file(csv_file)\n",
    "\n",
    "    audio_names = []\n",
    "    captions = []\n",
    "\n",
    "    for i, item in enumerate(csv_list):\n",
    "\n",
    "        audio_name = item['file_name']\n",
    "        if caption_field is not None:\n",
    "            item_captions = [_sentence_process(item[cap_ind], add_specials=False) for cap_ind in caption_field]\n",
    "        else:\n",
    "            item_captions = _sentence_process(item['caption'])\n",
    "        audio_names.append(audio_name)\n",
    "        captions.append(item_captions)\n",
    "\n",
    "    meta_dict = {'audio_name': np.array(audio_names), 'captions': np.array(captions)}\n",
    "\n",
    "    return meta_dict\n",
    "\n",
    "\n",
    "def _create_vocabulary(captions):\n",
    "    vocabulary = []\n",
    "    for caption in captions:\n",
    "        caption_words = caption.strip().split()\n",
    "        vocabulary.extend(caption_words)\n",
    "    words_list = list(set(vocabulary))\n",
    "    words_list.sort(key=vocabulary.index)\n",
    "    words_freq = [vocabulary.count(word) for word in words_list]\n",
    "    words_list.append('<sos>')\n",
    "    words_list.append('<eos>')\n",
    "    words_list.append('<ukn>')\n",
    "    words_freq.append(len(captions))\n",
    "    words_freq.append(len(captions))\n",
    "    words_freq.append(0)\n",
    "\n",
    "    return words_list, words_freq\n",
    "\n",
    "\n",
    "def _sentence_process(sentence, add_specials=False):\n",
    "\n",
    "    # transform to lower case\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    if add_specials:\n",
    "        sentence = '<sos> {} <eos>'.format(sentence)\n",
    "\n",
    "    # remove any forgotten space before punctuation and double space\n",
    "    sentence = sub(r'\\s([,.!?;:\"](?:\\s|$))', r'\\1', sentence).replace('  ', ' ')\n",
    "\n",
    "    # remove punctuations\n",
    "    sentence = sub('[,.!?;:\\\"]', ' ', sentence).replace('  ', ' ')\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def pad_or_truncate(x, audio_length):\n",
    "    \"\"\"Pad all audio to specific length.\"\"\"\n",
    "    length = len(x)\n",
    "    if length <= audio_length:\n",
    "        return np.concatenate((x, np.zeros(audio_length - length)), axis=0), length\n",
    "    else:\n",
    "        return x[:audio_length], audio_length\n",
    "\n",
    "    \n",
    "#######\n",
    "splits = ['train', 'val', 'test']\n",
    "sampling_rate = 32000\n",
    "audio_duration = 30\n",
    "max_audio_length = audio_duration * sampling_rate # 30 * 32000\n",
    "dataset='Clotho'\n",
    "\n",
    "data_path = '/home/clim-lab/바탕화면/main_drive/jiwon/retrieval/data/Clotho'\n",
    "csv_path = os.path.join(data_path, 'csv_files/')\n",
    "#csv_path = os.path.join(data_path, 'csv_files/train.csv')\n",
    "\n",
    "train_csv_path = os.path.join(csv_path, 'train.csv')\n",
    "\n",
    "\n",
    "#train_data 만 load 시키기\n",
    "train_csv_path = os.path.join(csv_path, 'train.csv')\n",
    "train_audio_dir = os.path.join(data_path, 'waveforms/train')\n",
    "train_hdf5_path = os.path.join(data_path, 'hdf5s/train/train.h5')\n",
    "\n",
    "train_meta_dict = load_metadata(dataset, train_csv_path)\n",
    "    # meta_dict: {'audio_names': [], 'captions': []}\n",
    "print(train_meta_dict)\n",
    "\n",
    "import pandas as pd\n",
    "pd.read_csv(train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2243367d-b39f-42a4-aaae-68cde869da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_name': array(['Distorted AM Radio noise.wav', 'Paper_Parchment_Rustling.wav',\n",
       "        '03 Whales Slowing Down.wav', ...,\n",
       "        'cold waterdrops in a hot pot.wav',\n",
       "        'Dry leaves falling on cement floor.wav', 'Wood chips.wav'],\n",
       "       dtype='<U133'),\n",
       " 'captions': array([['a muddled noise of broken channel of the tv',\n",
       "         'a television blares the rhythm of a static tv ',\n",
       "         'loud television static dips in and out of focus',\n",
       "         'the loud buzz of static constantly changes pitch and volume ',\n",
       "         'heavy static and the beginnings of a signal on a transistor radio'],\n",
       "        ['a person is turning a map over and over ',\n",
       "         'a person is very carefully rapping a gift for someone else ',\n",
       "         'a person is very carefully wrapping a gift for someone else ',\n",
       "         'he sighed as he turned the pages of the book stopping to scan the information ',\n",
       "         'papers are being turned stopped then turned again and someone is breathing '],\n",
       "        ['several barnyard animals mooing in a barn while it rains outside ',\n",
       "         'the vocalization of several whales along with the clicking of large numbers of shrimp reverberated below in the water ',\n",
       "         'underwater large numbers of shrimp clicking and several whales vocalizing ',\n",
       "         'whales sing to one another over the flowing water in the distance ',\n",
       "         'wales sing to one another with water flowing in the background'],\n",
       "        ...,\n",
       "        ['someone is flipping over food on a hot grill ',\n",
       "         'someone is flipping over food above a hot grill ',\n",
       "         'all recorded audio is drowned out by the loudness of the static ',\n",
       "         'someone waters down a boat with a high pressure stream of water ',\n",
       "         'a match is lit then another match is lit '],\n",
       "        ['tapping noises are being made before paper is being crumpled ',\n",
       "         'repeated tapping hits a hard surface and multiple papers shuffle ',\n",
       "         'a person is typing and pauses a few times in between strokes',\n",
       "         'they are continually dropping clips on the table ',\n",
       "         'sticks crunch and break while being walked on '],\n",
       "        ['some pounding in a room follows breaking of material that is not metal ',\n",
       "         'a stack of wooden blocks fall over and crash to the floor ',\n",
       "         'they are knocking down the toy blocks of the kid ',\n",
       "         'small blocks or chips are moving around and a muffled shuffling ',\n",
       "         'crushing up food to make a dish for others']], dtype='<U145')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d10028a4-1b8a-4ed2-98f1-b622287f1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, s1 = torchaudio.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]))\n",
    "a1_trans = torchaudio.functional.resample(a1, orig_freq=44100, new_freq = 32000)\n",
    "a11 = a1_trans.reshape(-1).numpy()\n",
    "a2, s2 = librosa.load(os.path.join('./data/Clotho/waveforms/train/', wav_path[1]), sr=32000)\n",
    "a2, audio_length2 = pad_or_truncate(a2, max_audio_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "75a5c6c6-a095-40c7-905e-dbbace134761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0004, 0.0007, 0.0007,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(a2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8991d356-1261-4e7e-8d4c-700f4aca8400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03096265, -0.01708653, -0.02846347, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 = torch.Tensor(a2.reshape(1,-1))\n",
    "a3_compose = compose_transform(a3)\n",
    "a3_transform_numpy = a3_compose.numpy()[0]\n",
    "a3_transform_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ed1b574-cafb-4cd5-85a5-b3c61cf08ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0004,  0.0007,  0.0007,  ..., -0.0023, -0.0022, -0.0018])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.functional.resample(a1, orig_freq=44100, new_freq = 32000).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2507849a-2d2a-434d-93e1-51e55aa83fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_transform = ComposeTransform([\n",
    "    RandomClip(sample_rate=sampling_rate, clip_length=64000),\n",
    "    RandomSpeedChange(sampling_rate),\n",
    "    RandomBackgroundNoise(sampling_rate, './data/musan/noise')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a44914e3-f6e3-4df6-9864-a26686e4cbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00850021, -0.00629861, -0.00925778, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.audio_augment import RandomClip, RandomSpeedChange, RandomBackgroundNoise, ComposeTransform\n",
    "#reshaping_a1 = torch.Tensor(a1.reshape(1,-1))\n",
    "transformed_audio = compose_transform(torch.Tensor(a1.reshape(1,-1)))\n",
    "transformed_audio_numpy = transformed_audio.numpy()[0] #torchaudio.load() returns a 2-dimensional tensor, select the first channel.\n",
    "\n",
    "transformed_audio_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "452c139c-a4f5-4037-9aeb-a16663550e5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'librosa' has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25729/3488200410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_augment_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_audio_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'librosa' has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "audio_name = 'fillerup.wav'\n",
    "new_filename = audio_name[:-4] + '_aug.wav'\n",
    "output_augment_path = os.path.join(data_path, 'waveforms/train_augment_only')\n",
    "output_path = os.path.join(output_augment_path, new_filename)\n",
    "\n",
    "librosa.output.write_wav(output_path, transformed_audio_numpy, sr = 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "272c5e67-7b50-473c-a6f4-75c607c73325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write(output_path, transformed_audio_numpy, 32000, format='WAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e69cfd36-8ea3-4698-9847-8078347bcab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3839/3839 [1:45:14<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from tools.audio_augment import RandomClip, RandomSpeedChange, RandomBackgroundNoise\n",
    "\n",
    "\n",
    "#path 지정해주기\n",
    "data_path = '/home/clim-lab/바탕화면/main_drive/jiwon/retrieval/data/Clotho'\n",
    "csv_path = os.path.join(data_path, 'csv_files/')\n",
    "\n",
    "train_csv_path = os.path.join(csv_path, 'train.csv')\n",
    "train_audio_dir = os.path.join(data_path, 'waveforms/train/')\n",
    "# train_hdf5_path = os.path.join(data_path, 'hdf5s/train/train.h5')\n",
    "\n",
    "train_meta_dict = load_metadata(dataset, train_csv_path)\n",
    "dataset='Clotho'\n",
    "\n",
    "\n",
    "compose_transform = ComposeTransform([\n",
    "    RandomClip(sample_rate=sampling_rate, clip_length=64000),\n",
    "    RandomSpeedChange(sampling_rate),\n",
    "    RandomBackgroundNoise(sampling_rate, './data/musan/noise')])\n",
    "\n",
    "    \n",
    "\n",
    "def augment_raw_audio(dataset, train_meta_dict):\n",
    "    '''\n",
    "    making raw audio augmentation using randomclip, randomnoise, randomspeedchange\n",
    "    file saved in './data/Clotho/waveforms/\n",
    "    '''\n",
    "\n",
    "    output_augment_path = os.path.join(data_path, 'waveforms/train_augment_only22')\n",
    "    audio_nums = len(train_meta_dict['audio_name'])\n",
    "\n",
    "    for i in tqdm(range(audio_nums)):\n",
    "        audio_name = train_meta_dict['audio_name'][i]\n",
    "\n",
    "        #using torchaudio.load\n",
    "        audio, sr = librosa.load(train_audio_dir + audio_name, sr=sampling_rate, mono=True)\n",
    "        #audio, audio_length = pad_or_truncate(audio, max_audio_length)\n",
    "                                 \n",
    "        audio_trans = torch.Tensor(audio.reshape(1,-1))\n",
    "        \n",
    "        new_filename = audio_name[:-4] + '_aug.wav'\n",
    "        output_path = os.path.join(output_augment_path, new_filename)\n",
    "\n",
    "\n",
    "        #대충 흐름은 이렇게 간다 \n",
    "        #audio augmentation 3가지 한방에 적용시키기\n",
    "        \n",
    "        transformed_audio = compose_transform(audio_trans)\n",
    "        transformed_audio_numpy = transformed_audio.numpy()[0] #torchaudio.load() returns a 2-dimensional tensor, select the first channel.\n",
    "\n",
    "\n",
    "        sf.write(output_path, transformed_audio_numpy, 32000, format='WAV')\n",
    "\n",
    "\n",
    "augment_raw_audio(dataset, train_meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f71af1-7297-4904-8f89-c1318f195f14",
   "metadata": {},
   "source": [
    "----\n",
    "### augment된 오디오에 대해서 캡션 csv 파일 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "77e0be56-63da-4ff0-ab25-8a2e89946cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_aug_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4d191e20-be55-4c8c-8ba0-406ed44b2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20061208.waves.02.wav\n",
      "20061208.waves.02\n",
      ".wav\n"
     ]
    }
   ],
   "source": [
    "b1, e1 = os.path.splitext(train_df['file_name'][171])\n",
    "print(train_df['file_name'][171])\n",
    "print(b1)\n",
    "print(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ac113975-3eae-4d2c-80d8-84a17b0e67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_aug_suffix(file_name):\n",
    "    base_name, ext = os.path.splitext(file_name)\n",
    "    if ext.lower() == \".wav\":\n",
    "        return base_name + \"_aug.wav\"\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "36e0cfaf-0571-4e30-acfe-833905cc7cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>caption_3</th>\n",
       "      <th>caption_4</th>\n",
       "      <th>caption_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>Ambience Birds.wav</td>\n",
       "      <td>A wild assortment of birds are chirping and ca...</td>\n",
       "      <td>Several different types of bird are tweeting a...</td>\n",
       "      <td>Birds tweeting and chirping happily, engine in...</td>\n",
       "      <td>An assortment of  wild birds are chirping and ...</td>\n",
       "      <td>Birds are chirping and making loud bird noises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>Ambience Birds_aug.wav</td>\n",
       "      <td>A wild assortment of birds are chirping and ca...</td>\n",
       "      <td>Several different types of bird are tweeting a...</td>\n",
       "      <td>Birds tweeting and chirping happily, engine in...</td>\n",
       "      <td>An assortment of  wild birds are chirping and ...</td>\n",
       "      <td>Birds are chirping and making loud bird noises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>typical neighborhood in Porto.wav</td>\n",
       "      <td>people talking to and over each other in a bus...</td>\n",
       "      <td>A child and a man are speaking to each other, ...</td>\n",
       "      <td>People in a busy market talk to and about each...</td>\n",
       "      <td>The man yells, as the child and the man are sp...</td>\n",
       "      <td>A couple of people are talking back and forth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7241</th>\n",
       "      <td>typical neighborhood in Porto_aug.wav</td>\n",
       "      <td>people talking to and over each other in a bus...</td>\n",
       "      <td>A child and a man are speaking to each other, ...</td>\n",
       "      <td>People in a busy market talk to and about each...</td>\n",
       "      <td>The man yells, as the child and the man are sp...</td>\n",
       "      <td>A couple of people are talking back and forth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>&amp;quot;BCat Bites a Bit&amp;quot; .wav</td>\n",
       "      <td>The man is repeating words over and over with ...</td>\n",
       "      <td>A person with a clear voice is repeating some ...</td>\n",
       "      <td>A woman is repeating what she says at normal v...</td>\n",
       "      <td>Somebody speaks out loud and  endlessly repeat...</td>\n",
       "      <td>A young person repeats his words while trying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>young goat bleating in a stable_aug.wav</td>\n",
       "      <td>A goat is bleating loudly while people are spe...</td>\n",
       "      <td>A goat bleats noisily while people in the back...</td>\n",
       "      <td>A goat bleats loudly as time goes by, while pe...</td>\n",
       "      <td>a goat bleats loudly as time goes on while peo...</td>\n",
       "      <td>Humans chatter among themselves as a lamb is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>zipper.wav</td>\n",
       "      <td>A long zipper is tested by being repeatedly pu...</td>\n",
       "      <td>A zipper is being opened and closed quickly.</td>\n",
       "      <td>Someone is rapidly zipping and unzipping a zip...</td>\n",
       "      <td>a really long zipper is being pulled and teste...</td>\n",
       "      <td>a zipper being opened and closed at varying sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>zipper_aug.wav</td>\n",
       "      <td>A long zipper is tested by being repeatedly pu...</td>\n",
       "      <td>A zipper is being opened and closed quickly.</td>\n",
       "      <td>Someone is rapidly zipping and unzipping a zip...</td>\n",
       "      <td>a really long zipper is being pulled and teste...</td>\n",
       "      <td>a zipper being opened and closed at varying sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>zippers01.wav</td>\n",
       "      <td>A jacket or bag is being zipped and unzipped.</td>\n",
       "      <td>A long zipper is clasped frequently back and f...</td>\n",
       "      <td>A zipper to a suitcase is being opened and clo...</td>\n",
       "      <td>Long zipper being zipped back and forth multip...</td>\n",
       "      <td>The zipper is opened and closed at a slow pace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>zippers01_aug.wav</td>\n",
       "      <td>A jacket or bag is being zipped and unzipped.</td>\n",
       "      <td>A long zipper is clasped frequently back and f...</td>\n",
       "      <td>A zipper to a suitcase is being opened and clo...</td>\n",
       "      <td>Long zipper being zipped back and forth multip...</td>\n",
       "      <td>The zipper is opened and closed at a slow pace.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_name  \\\n",
       "3614                       Ambience Birds.wav   \n",
       "7453                   Ambience Birds_aug.wav   \n",
       "3402        typical neighborhood in Porto.wav   \n",
       "7241    typical neighborhood in Porto_aug.wav   \n",
       "3285        &quot;BCat Bites a Bit&quot; .wav   \n",
       "...                                       ...   \n",
       "7573  young goat bleating in a stable_aug.wav   \n",
       "632                                zipper.wav   \n",
       "4471                           zipper_aug.wav   \n",
       "709                             zippers01.wav   \n",
       "4548                        zippers01_aug.wav   \n",
       "\n",
       "                                              caption_1  \\\n",
       "3614  A wild assortment of birds are chirping and ca...   \n",
       "7453  A wild assortment of birds are chirping and ca...   \n",
       "3402  people talking to and over each other in a bus...   \n",
       "7241  people talking to and over each other in a bus...   \n",
       "3285  The man is repeating words over and over with ...   \n",
       "...                                                 ...   \n",
       "7573  A goat is bleating loudly while people are spe...   \n",
       "632   A long zipper is tested by being repeatedly pu...   \n",
       "4471  A long zipper is tested by being repeatedly pu...   \n",
       "709       A jacket or bag is being zipped and unzipped.   \n",
       "4548      A jacket or bag is being zipped and unzipped.   \n",
       "\n",
       "                                              caption_2  \\\n",
       "3614  Several different types of bird are tweeting a...   \n",
       "7453  Several different types of bird are tweeting a...   \n",
       "3402  A child and a man are speaking to each other, ...   \n",
       "7241  A child and a man are speaking to each other, ...   \n",
       "3285  A person with a clear voice is repeating some ...   \n",
       "...                                                 ...   \n",
       "7573  A goat bleats noisily while people in the back...   \n",
       "632        A zipper is being opened and closed quickly.   \n",
       "4471       A zipper is being opened and closed quickly.   \n",
       "709   A long zipper is clasped frequently back and f...   \n",
       "4548  A long zipper is clasped frequently back and f...   \n",
       "\n",
       "                                              caption_3  \\\n",
       "3614  Birds tweeting and chirping happily, engine in...   \n",
       "7453  Birds tweeting and chirping happily, engine in...   \n",
       "3402  People in a busy market talk to and about each...   \n",
       "7241  People in a busy market talk to and about each...   \n",
       "3285  A woman is repeating what she says at normal v...   \n",
       "...                                                 ...   \n",
       "7573  A goat bleats loudly as time goes by, while pe...   \n",
       "632   Someone is rapidly zipping and unzipping a zip...   \n",
       "4471  Someone is rapidly zipping and unzipping a zip...   \n",
       "709   A zipper to a suitcase is being opened and clo...   \n",
       "4548  A zipper to a suitcase is being opened and clo...   \n",
       "\n",
       "                                              caption_4  \\\n",
       "3614  An assortment of  wild birds are chirping and ...   \n",
       "7453  An assortment of  wild birds are chirping and ...   \n",
       "3402  The man yells, as the child and the man are sp...   \n",
       "7241  The man yells, as the child and the man are sp...   \n",
       "3285  Somebody speaks out loud and  endlessly repeat...   \n",
       "...                                                 ...   \n",
       "7573  a goat bleats loudly as time goes on while peo...   \n",
       "632   a really long zipper is being pulled and teste...   \n",
       "4471  a really long zipper is being pulled and teste...   \n",
       "709   Long zipper being zipped back and forth multip...   \n",
       "4548  Long zipper being zipped back and forth multip...   \n",
       "\n",
       "                                              caption_5  \n",
       "3614    Birds are chirping and making loud bird noises.  \n",
       "7453    Birds are chirping and making loud bird noises.  \n",
       "3402     A couple of people are talking back and forth.  \n",
       "7241     A couple of people are talking back and forth.  \n",
       "3285  A young person repeats his words while trying ...  \n",
       "...                                                 ...  \n",
       "7573  Humans chatter among themselves as a lamb is b...  \n",
       "632   a zipper being opened and closed at varying sp...  \n",
       "4471  a zipper being opened and closed at varying sp...  \n",
       "709     The zipper is opened and closed at a slow pace.  \n",
       "4548    The zipper is opened and closed at a slow pace.  \n",
       "\n",
       "[7678 rows x 6 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug_df[\"file_name\"] = train_aug_df[\"file_name\"].apply(add_aug_suffix)\n",
    "train_df_all = pd.concat([train_df, train_aug_df], ignore_index=True)\n",
    "display(train_df_all.sort_values(by='file_name', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a603ac99-acb1-4b17-b08d-48181a857a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_aug_df.to_csv('./data/Clotho/csv_files/train_augment_only.csv', index=False)\n",
    "# train_df_all.to_csv('./data/Clotho/csv_files/train_augment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c64d13eb-f072-43ef-9533-a20a24a682e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3836"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3836"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df['caption_1'].nunique())\n",
    "display(train_df_all['caption_1'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2636a9d-68e7-48fb-9a30-b81dd48c8b95",
   "metadata": {},
   "source": [
    "----\n",
    "### train augment 된 데이터와 기존 train 데이터 폴더들 합치기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "23fea6b6-44bf-471d-ab8a-4a299f5d6e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files from train waveforms: 100%|██████████████████████████████████████| 3839/3839 [00:06<00:00, 553.28file/s]\n",
      "Copying files from augmented train waveform: 100%|██████████████████████████████| 3839/3839 [02:08<00:00, 29.92file/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def merge_folders(source_folder1, source_folder2, merge_folder):\n",
    "    '''\n",
    "    두 개의 폴더 내용물을 합쳐서 새로운 폴더를 만듦\n",
    "    '''\n",
    "    # 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(merge_folder):\n",
    "        os.makedirs(merge_folder)\n",
    "\n",
    "    # source_folder1의 파일 -> merge_folder로 복사\n",
    "    for filename in tqdm(os.listdir(source_folder1), desc=\"Copying files from train waveforms\", unit=\"file\"):\n",
    "        src = os.path.join(source_folder1, filename)\n",
    "        dst = os.path.join(merge_folder, filename)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # source_folder2의 파일 -> merge_folder로 복사\n",
    "    for filename in tqdm(os.listdir(source_folder2), desc=\"Copying files from augmented train waveform\", unit=\"file\"):\n",
    "        src = os.path.join(source_folder2, filename)\n",
    "        dst = os.path.join(merge_folder, filename)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "#경로 지정\n",
    "source_folder1 = './data/Clotho/waveforms/train' \n",
    "source_folder2 = './data/Clotho/waveforms/train_augment_only' \n",
    "merge_folder = './data/Clotho/waveforms/train_augment'  # 전체 합칠 폴더 경로\n",
    "\n",
    "merge_folders(source_folder1, source_folder2, merge_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7488f04-a97b-49b2-adce-189a8001bff4",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d1ed2-f0b3-454e-9055-194a425b53bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### csv 파일에 있는 file_name 과 train_augment 폴더에 있는 파일들 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2eed951b-3adf-4ed6-9ae6-53f4cfd9e3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing files in 'train_augment' folder:\n",
      "No missing files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def check_missing_files(csv_file_path, augment_folder_path):\n",
    "    #logger사용해서 찍기\n",
    "    logger = logging.getLogger(\"missing_files_logger\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Create a console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Add the console handler to the logger\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    \n",
    "    #csv 파일 위치와 file_name 불러오기\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    csv_filenames = data['file_name'].tolist()\n",
    "\n",
    "    #augment한 waveform 파일 이름들 불러오기\n",
    "    augment_filenames = os.listdir(augment_folder_path)\n",
    "\n",
    "    # Find missing files in 'train_augment' folder\n",
    "    missing_files = [filename for filename in csv_filenames if filename not in augment_filenames]\n",
    "    \n",
    "    # Log the missing files\n",
    "    logger.info(\"Missing files in 'train_augment' folder:\")\n",
    "    if not missing_files:\n",
    "        logger.info(\"No missing files\")\n",
    "    else:\n",
    "        for filename in missing_files:\n",
    "            logger.info(filename)\n",
    "\n",
    "    return missing_files\n",
    "\n",
    "csv_file_path = './data/Clotho/csv_files/train_augment.csv'\n",
    "augment_folder_path = './data/Clotho/waveforms/train_augment' \n",
    "\n",
    "check_missing_files(csv_file_path, augment_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99c89d-ced5-45ad-bdfe-7bcf1c9659c0",
   "metadata": {},
   "source": [
    "----\n",
    "### h5 train file 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b7998119-0740-4762-869f-611783eeee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.dataset import load_metadata, pad_or_truncate, _create_vocabulary, _sentence_process\n",
    "from tools.dataset import pack_dataset_to_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "04fe97d1-aee0-4dfc-9374-94838fc76297",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pack_augment_dataset_to_hdf5' from 'tools.dataset' (/home/clim-lab/바탕화면/main_drive/jiwon/retrieval/tools/dataset.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25729/1439619147.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpack_augment_dataset_to_hdf5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pack_augment_dataset_to_hdf5' from 'tools.dataset' (/home/clim-lab/바탕화면/main_drive/jiwon/retrieval/tools/dataset.py)"
     ]
    }
   ],
   "source": [
    "from tools.dataset import pack_augment_dataset_to_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf34e4eb-3862-4bfb-b97b-ada40871cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████▏                                    | 4010/7678 [33:02<30:13,  2.02it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Clotho/waveforms/train_augment/20061208_aug.waves.02_aug.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    654\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'data/Clotho/waveforms/train_augment/20061208_aug.waves.02_aug.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25729/2986396670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpack_augment_dataset_to_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Clotho'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25729/1927313486.py\u001b[0m in \u001b[0;36mpack_augment_dataset_to_hdf5\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0maudio_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maudio_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_or_truncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_audio_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m#이미 augment할때 잘라버림..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retrieval/lib/python3.7/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Clotho/waveforms/train_augment/20061208_aug.waves.02_aug.wav'"
     ]
    }
   ],
   "source": [
    "def pack_augment_dataset_to_hdf5(dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        dataset: 'AudioCaps', 'Clotho'\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    splits = ['train_augment', 'val', 'test']\n",
    "    sampling_rate = 32000\n",
    "    all_captions = [] \n",
    "    #csv file에 있는 caption들을 list로 한번에 저장 ex) train data -> 3839*5 = 19195개 caption 저장\n",
    "    \n",
    "    #if dataset == 'AudioCaps':\n",
    "    #    audio_duration = 10\n",
    "    if dataset == 'Clotho':\n",
    "        audio_duration = 30\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(f'No dataset named: {dataset}')\n",
    "\n",
    "    max_audio_length = audio_duration * sampling_rate # 30 * 32000\n",
    "    \n",
    "    \n",
    "    for split in splits:\n",
    "        csv_path = 'data/{}/csv_files/{}.csv'.format(dataset, split)\n",
    "        audio_dir = 'data/{}/waveforms/{}/'.format(dataset, split)\n",
    "        \n",
    "        if split=='train_augment':\n",
    "            hdf5_path = 'data/{}/hdf5s/{}/'.format(dataset, split)\n",
    "              \n",
    "        else:\n",
    "            hdf5_path = 'data/{}/hdf5s/{}_augment/'.format(dataset, split)\n",
    "\n",
    "            \n",
    "        # make dir for hdf5\n",
    "        Path(hdf5_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        meta_dict = load_metadata(dataset, csv_path)\n",
    "        # meta_dict: {'audio_names': [], 'captions': []}\n",
    "\n",
    "        audio_nums = len(meta_dict['audio_name'])\n",
    "\n",
    "        if split == 'train_augment':\n",
    "            # store all captions in training set into a list\n",
    "            if dataset == 'Clotho':\n",
    "                for caps in meta_dict['captions']:\n",
    "                    for cap in caps:\n",
    "                        all_captions.append(cap)\n",
    "            else:\n",
    "                all_captions.extend(meta_dict['captions'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "\n",
    "        with h5py.File(hdf5_path+'{}.h5'.format(split), 'w') as hf:\n",
    "\n",
    "            hf.create_dataset('audio_name', shape=(audio_nums,), dtype=h5py.special_dtype(vlen=str))\n",
    "            hf.create_dataset('audio_length', shape=(audio_nums,), dtype=np.uint32)\n",
    "            hf.create_dataset('waveform', shape=(audio_nums, max_audio_length), dtype=np.float32)\n",
    "\n",
    "            if split == 'train' and dataset == 'AudioCaps':\n",
    "                hf.create_dataset('caption', shape=(audio_nums,), dtype=h5py.special_dtype(vlen=str))\n",
    "            \n",
    "            else: #'clotho dataset'\n",
    "                hf.create_dataset('caption', shape=(audio_nums, 5), dtype=h5py.special_dtype(vlen=str))\n",
    "\n",
    "            for i in tqdm(range(audio_nums)):\n",
    "                audio_name = meta_dict['audio_name'][i]\n",
    "\n",
    "                audio, _ = librosa.load(audio_dir + audio_name, sr=sampling_rate, mono=True)\n",
    "                audio, audio_length = pad_or_truncate(audio, max_audio_length) \n",
    "                #이미 augment할때 잘라버렸는데... \n",
    "                \n",
    "\n",
    "                hf['audio_name'][i] = audio_name.encode()\n",
    "                hf['audio_length'][i] = audio_length\n",
    "                hf['waveform'][i] = audio\n",
    "                hf['caption'][i] = meta_dict['captions'][i]\n",
    "\n",
    "        logger.info(f'Packed {split} set to {hdf5_path} using {time.time() - start_time} s.')\n",
    "    \n",
    "    words_list, words_freq = _create_vocabulary(all_captions)\n",
    "    # 총 4368개(augment전)\n",
    "    \n",
    "    logger.info(f'Creating vocabulary: {len(words_list)} tokens!')\n",
    "    write_pickle_file(words_list, 'data/{}/pickles/words_list_augment.p'.format(dataset))\n",
    "    \n",
    "pack_augment_dataset_to_hdf5('Clotho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fa7706bc-a392-4c1d-8b17-cc995e3114ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_augment_dataset_to_hdf5(dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        dataset: 'AudioCaps', 'Clotho'\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    splits = ['train_augment', 'val', 'test']\n",
    "    sampling_rate = 32000\n",
    "    all_captions = [] \n",
    "    #csv file에 있는 caption들을 list로 한번에 저장 ex) train data -> 3839*5 = 19195개 caption 저장\n",
    "    \n",
    "    #if dataset == 'AudioCaps':\n",
    "    #    audio_duration = 10\n",
    "    if dataset == 'Clotho':\n",
    "        audio_duration = 30\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(f'No dataset named: {dataset}')\n",
    "\n",
    "    max_audio_length = audio_duration * sampling_rate # 30 * 32000\n",
    "    \n",
    "    for split in splits:\n",
    "        csv_path = 'data/{}/csv_files/{}.csv'.format(dataset, split)\n",
    "        audio_dir = 'data/{}/waveforms/{}/'.format(dataset, split)\n",
    "        \n",
    "        if split=='train_augment':\n",
    "            hdf5_path = 'data/{}/hdf5s/{}/'.format(dataset, split)\n",
    "              \n",
    "        else:\n",
    "            hdf5_path = 'data/{}/hdf5s/{}_augment/'.format(dataset, split)\n",
    "\n",
    "            \n",
    "        # make dir for hdf5\n",
    "        Path(hdf5_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        meta_dict = load_metadata(dataset, csv_path)\n",
    "        # meta_dict: {'audio_names': [], 'captions': []}\n",
    "\n",
    "        audio_nums = len(meta_dict['audio_name'])\n",
    "\n",
    "        if split == 'train_augment':\n",
    "            # store all captions in training set into a list\n",
    "            if dataset == 'Clotho':\n",
    "                for caps in meta_dict['captions']:\n",
    "                    for cap in caps:\n",
    "                        all_captions.append(cap)\n",
    "            else:\n",
    "                all_captions.extend(meta_dict['captions'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            with h5py.File(hdf5_path+'{}.h5'.format(split), 'w') as hf:\n",
    "\n",
    "                hf.create_dataset('audio_name', shape=(audio_nums,), dtype=h5py.special_dtype(vlen=str))\n",
    "                hf.create_dataset('audio_length', shape=(audio_nums,), dtype=np.uint32)\n",
    "                hf.create_dataset('waveform', shape=(audio_nums, max_audio_length), dtype=np.float32)\n",
    "\n",
    "                if split == 'train' and dataset == 'AudioCaps':\n",
    "                    hf.create_dataset('caption', shape=(audio_nums,), dtype=h5py.special_dtype(vlen=str))\n",
    "\n",
    "                else: #'clotho dataset'\n",
    "                    hf.create_dataset('caption', shape=(audio_nums, 5), dtype=h5py.special_dtype(vlen=str))\n",
    "\n",
    "                for i in tqdm(range(audio_nums)):\n",
    "                    audio_name = meta_dict['audio_name'][i]\n",
    "\n",
    "                    audio, _ = librosa.load(audio_dir + audio_name, sr=sampling_rate, mono=True)\n",
    "                    audio, audio_length = pad_or_truncate(audio, max_audio_length) \n",
    "                    \n",
    "\n",
    "\n",
    "                    hf['audio_name'][i] = audio_name.encode()\n",
    "                    hf['audio_length'][i] = audio_length\n",
    "                    hf['waveform'][i] = audio\n",
    "                    hf['caption'][i] = meta_dict['captions'][i]\n",
    "        except FileNotFoundError as F:\n",
    "            print(\"file not found\", F)\n",
    "        except ValueError:\n",
    "            print(\"Invalid value.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            \n",
    "\n",
    "        logger.info(f'Packed {split} set to {hdf5_path} using {time.time() - start_time} s.')\n",
    "    \n",
    "    words_list, words_freq = _create_vocabulary(all_captions)\n",
    "    # 총 4368개(augment전)\n",
    "    \n",
    "    logger.info(f'Creating vocabulary: {len(words_list)} tokens!')\n",
    "    write_pickle_file(words_list, 'data/{}/pickles/words_list_augment.p'.format(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c4f87-4656-4349-b3da-591e1124c4d3",
   "metadata": {},
   "source": [
    "- 새로만든 폴더 train_augment폴더에 다시 합쳐서 만들기 -> **DONE** \n",
    "- csv 파일 만들때 suffix나 정규식 사용해서 확장자일 경우에만 분리하도록 코드 다시짜기 -> **DONE** \n",
    "- 오디오 파일 os.listdir 해서 여기에 있는 오디오 이름들이 csv_file에도 있는지 확인코드 짜기 -> **DONE** \n",
    "- data_augment.py 실행시켜서 h5py 파일 생성하기 -> 돌리기 전에 코드 세세히 보고 수정하기 -> **DONE** \n",
    "- h5py파일 만들때 try except 구문 넣어서 예외처리생겼을 떄는 로그만 찍고 넘어가기 -> **DONE** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ea261-70ae-4362-a93b-bc59b5244d2b",
   "metadata": {},
   "source": [
    "hdf5파일 만들어지면 폴더 잘 생성되었는지, audio length 제대로 됐는지 확인하기 -> **DONE**      \n",
    "-> 기존보다 더 짧게 됐네...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "65192eeb-2328-4e11-96a0-dadb5f64fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/clim-lab/바탕화면/main_drive/jiwon/retrieval/data/Clotho'\n",
    "train_h5_path = os.path.join(data_path, 'hdf5s/train_augment/train_augment.h5')\n",
    "val_h5_path = os.path.join(data_path, 'hdf5s/val/val.h5')\n",
    "test_h5_path = os.path.join(data_path, 'hdf5s/test/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "70a64033-a9b6-422c-ad3a-16125569b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(train_h5_path, 'r') as hf:\n",
    "    train_audio_keys = [audio_name.decode() for audio_name in hf['audio_name'][:]]\n",
    "    # audio_names: [str] \n",
    "    train_audio_lengths = [length for length in hf['audio_length'][:]]\n",
    "                # [cap_1, cap_2, ..., cap_5]\n",
    "    train_captions = hf['caption'][:]\n",
    "    \n",
    "with h5py.File(val_h5_path, 'r') as hf:\n",
    "    val_audio_keys = [audio_name.decode() for audio_name in hf['audio_name'][:]]\n",
    "    # audio_names: [str] \n",
    "    val_audio_lengths = [length for length in hf['audio_length'][:]]\n",
    "    val_captions = hf['caption'][:]\n",
    "    \n",
    "with h5py.File(test_h5_path, 'r') as hf:\n",
    "    test_audio_keys = [audio_name.decode() for audio_name in hf['audio_name'][:]]\n",
    "    # audio_names: [str] \n",
    "    test_audio_lengths = [length for length in hf['audio_length'][:]]\n",
    "    test_captions = hf['caption'][:]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4a1c425e-b9da-4f38-b8d1-f1b6aaf4d4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "길이 비교\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "645889.61747851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "723793.4411483253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "717054.9693779905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train_audio_keys))\n",
    "display(len(val_audio_keys))\n",
    "display(len(test_audio_keys))\n",
    "\n",
    "print(\"길이 비교\")\n",
    "display(sum(train_audio_lengths)/len(train_audio_lengths))\n",
    "display(sum(val_audio_lengths)/len(val_audio_lengths))\n",
    "display(sum(test_audio_lengths)/len(test_audio_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "02932ab3-26c9-4114-a2dc-dc4fe56e38a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'a muddled noise of broken channel of the tv',\n",
       "        b'a television blares the rhythm of a static tv ',\n",
       "        b'loud television static dips in and out of focus',\n",
       "        b'the loud buzz of static constantly changes pitch and volume ',\n",
       "        b'heavy static and the beginnings of a signal on a transistor radio'],\n",
       "       [b'a person is turning a map over and over ',\n",
       "        b'a person is very carefully rapping a gift for someone else ',\n",
       "        b'a person is very carefully wrapping a gift for someone else ',\n",
       "        b'he sighed as he turned the pages of the book stopping to scan the information ',\n",
       "        b'papers are being turned stopped then turned again and someone is breathing '],\n",
       "       [b'several barnyard animals mooing in a barn while it rains outside ',\n",
       "        b'the vocalization of several whales along with the clicking of large numbers of shrimp reverberated below in the water ',\n",
       "        b'underwater large numbers of shrimp clicking and several whales vocalizing ',\n",
       "        b'whales sing to one another over the flowing water in the distance ',\n",
       "        b'wales sing to one another with water flowing in the background']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
